{"cells":[{"metadata":{"_uuid":"a44db9be7ef883e7c95c85b919b1cd3048139824"},"cell_type":"markdown","source":"Nisarg Patel  \nCSC 578- NN and Deep Learning"},{"metadata":{"_uuid":"659cfc77618950a0517c40946c65191704be7257"},"cell_type":"markdown","source":"Problem Statement : The task of the competition is to predict the temperature at the next hour given the weather conditions and temperature for prior hours.  This is a multivariate timeseries forecasting problem, and we use a neural network approach to tackle the problem."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nimport tensorflow as tf\nfrom matplotlib import pyplot\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport keras\nkeras.__version__\npd.set_option('display.max_rows',50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7d4c98cb831956be72d655f72cac2b39313a614"},"cell_type":"code","source":"dataset = pd.read_csv(\"../input/climate_hour.csv\") #,header=0, index_col=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"45a12453c252591f2387dca2a7faf54e80332766"},"cell_type":"code","source":"dataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f829320cee45bdf5fbda1fd1b64ca9d7ec306152"},"cell_type":"code","source":"dataset.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb7f5d9931de19612f54463d2030773a7021f088"},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission.csv')\nsubmission = submission['date_time']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data_dir = '../input/'\nfname = os.path.join(data_dir, 'climate_hour.csv')\n\nf = open(fname)\ndata = f.read()\nf.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe03f7c5ed55b10031ddcc1528e45e39d9ecad14"},"cell_type":"code","source":"lines = data.split('\\n')\nheader = lines[0].split(',')\nlines = lines[1:]\n\nprint(header)\nprint(len(lines))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0377ee3faac0948206260514a037f9abc407c85"},"cell_type":"code","source":"del lines[70037]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a1de6df7db852203052ea96eef1f9cca5b64c3b"},"cell_type":"code","source":"import numpy as np\n\n# Parse the data\n\nfloat_data = np.zeros((len(lines), len(header) - 1))\nfor i, line in enumerate(lines):\n    values = [float(x) for x in line.split(',')[1:]]\n    float_data[i, :] = values\nprint(float_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ebc1d945400e32c28d7182d6b3d1baca97addf1"},"cell_type":"code","source":"temp = float_data[:, 1]\nplt.plot(range(1440), temp[:1440]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"445ef0c9d3fafdd4ebfe94eedeb6471ab84f39af"},"cell_type":"code","source":"float_data[0:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fbbe0f9f4e21533a9bc9f1a02895738864902a23"},"cell_type":"code","source":"dataset[dataset['Date Time']=='31.12.2014 22:00:00'] # to find the index for split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94519527612f6744f120e54d19b595c0a4d0ffd2"},"cell_type":"code","source":"def series_to_supervised(mat,lookback,future_step=1):\n    '''\n    Convert a timeseries as a supervised learning dataset.\n    References:\n    https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/\n    Arguments:\n        mat: [np.ndarray] a numpy nd array object with values in float format\n        lookback: [int] number of timeframes to look back in past (t-n,...,t-1). This does not include current time frame (t)\n                E.g. to look 24 hours data including current time-stamp, this value should be 23 (t-23,..,t-1 and t(covered in future_step)).\n        future_step: [int] number of timeframes to look in future (t,t+1,..,t+n). This includes the current time frame (t).\n                E.g. to look 1 timeframe ahead in future, the value should be 2 (t and t+1).        \n    Returns:\n        A pandas data frame with timeseries framed for supervised learning.\n    '''\n    \n    n_vars = mat.shape[-1]\n    df = pd.DataFrame(mat)\n\n    cols,names = list(),list()\n    #create input sequence (t-n,....,t-1)\n    for i in range(lookback,0,-1):\n        cols.append(df.shift(i))\n        names+=[('var%d(t-%d)'%(j+1,i)) for j in range(n_vars)]\n    #create forecast sequence (t,t+1,..,t+n)\n    for i in range(0,future_step):\n        cols.append(df.shift(-i))\n        if i==0:\n            names+=[('var%d(t)'%(j+1)) for j in range(n_vars)]\n        else:\n            names+=[('var%d(t+%d)'%(j+1,i)) for j in range(n_vars)]\n    #concatenate all columns\n    agg = pd.concat(cols,axis=1)\n    agg.columns = names\n    #drop nulls\n    agg.dropna(inplace=True)\n    return agg","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f048dfd0a51a1ca4a60b56ffc25d7a6a372ad545"},"cell_type":"markdown","source":"## Dividing the data into training and testing \nwe will split the data from 01.01.2009 01:00:00  to 31.12.2014 22:00:00 into traing data and 31.12.2014 00:00:00 to 1.12.2016 23:00:00 into testing data"},{"metadata":{"trusted":true,"_uuid":"3ce689848569317494f0024bd3a0f749094cbb18"},"cell_type":"code","source":"lookback = 23\nfuture_step = 2\n\n#create train_data\ntrain = series_to_supervised(float_data[:52564+future_step],23,2)\n# Seperate the samples and target variables\nx_train = train.iloc[:,:336]\ny_train = train.iloc[:,337]\n\n#create test_data\ntest = series_to_supervised(float_data[52565-lookback:],lookback,future_step)\n\n# Seperate the samples and target variables\nx_test = test.iloc[:,:336]\ny_test = test.iloc[:,337]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b834644a87c989abbc7e9ff1ba0567be1690f4c9"},"cell_type":"markdown","source":"### Converting the 2-D data into 3-D"},{"metadata":{"trusted":true,"_uuid":"191fdb0401a4b7bf57f2c6bf5a1e56d963f87ee8"},"cell_type":"code","source":"print(\"X_train data\")\nprint(x_train.head(3))\nprint(x_train.tail(3))\nprint(\"\\n X_test data\")\nprint(x_test.head(3))\nprint(x_test.tail(3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4733ac01f097492bb76515c395cedd61d56a340","scrolled":false},"cell_type":"code","source":"print(\"Y_train data\")\nprint(y_train.head(3))\nprint(y_train.tail(3))\nprint(\"\\nY_test data\")\nprint(y_test.head(3))\nprint(y_test.tail(3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e87c9adf062a5960feccf2f3c24eb065b61ab470","scrolled":true},"cell_type":"code","source":"train_X = x_train.values.reshape((x_train.shape[0],1, x_train.shape[1]))\ntest_X = x_test.values.reshape((x_test.shape[0],1, x_test.shape[1]))\nprint(train_X.shape, y_train.shape, test_X.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb95098709e2d8f1a2199dd386155019f2cddf7b"},"cell_type":"markdown","source":"### Building baseline model using 1 layer of LSTM"},{"metadata":{"trusted":true,"_uuid":"326c10690e605fcf1946b98156038aa9fde4b33f"},"cell_type":"code","source":"import time\nfrom math import sqrt\nfrom pandas import DataFrame\nfrom pandas import concat\n\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout,Activation\nfrom keras.layers import Embedding\nfrom keras.layers import LSTM, GRU\nfrom keras.layers import concatenate\nfrom keras import optimizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb925255ac15a3169451344f5db9cb32f14f2834"},"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\nmodel.add(Dense(1))\nmodel.compile(loss='mae', optimizer='adam')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"3b1c7d606bf4e00b764318f65fcd1977a723d1b1"},"cell_type":"code","source":"# fit network\nmodel.fit(train_X, y_train, epochs=30, batch_size=72, validation_split=0.1, verbose=2, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"c14bf7dedb7401b6b6813205581f459ff492a9be"},"cell_type":"code","source":"# plot history\npyplot.plot(history.history['loss'], label='train')\npyplot.plot(history.history['val_loss'], label='test')\npyplot.xlabel(\"Epochs\")\npyplot.ylabel(\"Loss\")\npyplot.legend()\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80758f154ae9f8985c0e66f5e44e9abef3ddaad9"},"cell_type":"code","source":"predict = model.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"febcb92f9bb4841c5d0e723be1578233aa45774f"},"cell_type":"code","source":"columns_new = ['temperature']\npredict = pd.DataFrame(predict, columns=columns_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"327dbe74ae49402d4f426ffdaa3e86ea71be0b9e"},"cell_type":"code","source":"frames = [submission,ypred]\nsubmission1 = pd.concat([submission,ypred], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"665c5617c2a6c068d0db3d87b5658d8e626a669f"},"cell_type":"code","source":"submission1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ecb5b51c6e52abd700b8c7e286d5e3d8b1bc1401"},"cell_type":"code","source":"submission1.to_csv('submission1.csv', index= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bfde64e046e018f8fe5486f5cbafdd24a2929ca"},"cell_type":"code","source":"'''test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n# invert scaling for forecast\ninv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\ninv_yhat = scaler.inverse_transform(inv_yhat)\ninv_yhat = inv_yhat[:,0]\n# invert scaling for actual\ny_test = y_test.reshape((len(y_test), 1))\ninv_y = concatenate((y_test, test_X[:, 1:]), axis=1)\ninv_y = scaler.inverse_transform(inv_y)\ninv_y = inv_y[:,0]\n# calculate RMSE\nrmse = sqrt(mean_squared_error(inv_y, inv_yhat))\nprint('Test RMSE: %.3f' % rmse) '''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93dcae774b508c656c1aad55145d8fac2b20fc1a"},"cell_type":"markdown","source":"### Model 2"},{"metadata":{"trusted":true,"_uuid":"596aef4e4a821549afff9c93a4046cb47db209b3","scrolled":true},"cell_type":"code","source":"model2 = Sequential()\nmodel2.add(LSTM(512, return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])))\nmodel2.add(Dropout(0.5))\nmodel2.add(LSTM(512))\nmodel2.add(Dropout(0.5))\nmodel2.add(Dense(1))\nmodel2.add(Activation(\"linear\"))\nmodel2.compile(loss=\"mae\", optimizer=\"adam\")\nmodel2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"28b2572dccb98c7f0ba8ba2e116d5493c275c234"},"cell_type":"code","source":"start = time.time()\nmodel2.fit(train_X, y_train, batch_size=70, epochs =20,\n           validation_split=0.1, verbose = 2)\nprint(\"---> Compilation Time : \", time.time() - start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6832c84071e1b296f82626df6d8398a46cd6f77e"},"cell_type":"code","source":"pred2 = model2.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d11d539849b391418d570cbd9659fafc94bbbcb"},"cell_type":"code","source":"columns_new = ['temperature']\npredict2 = pd.DataFrame(pred2, columns=columns_new)\nsubmission2 = pd.concat([submission,predict2], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ddff78599b3606d91574d683fae2765030acc2f"},"cell_type":"code","source":"submission2.to_csv('submission2.csv', index= False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b14693e9deaaf0366dae2f40839550fc00b4526"},"cell_type":"markdown","source":"### Model 3"},{"metadata":{"trusted":true,"_uuid":"a908f7ada627d6872c4e982477a96f8962506b2d"},"cell_type":"code","source":"scaler = MinMaxScaler(feature_range=(0, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"faba7507c039423904283b7a37e857da9a474be1"},"cell_type":"code","source":"x_train_norm = scaler.fit_transform(x_train)\nx_test_norm = scaler.fit_transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbc25fdcc6c6e6b12264b22fadf745e89867e85f"},"cell_type":"code","source":"#train_X_norm = x_train_norm.values.reshape((x_train_norm[0],1,x_train_norm[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbc77ce2f2e6adf8b9a38e3e24081fde6072f477","scrolled":true},"cell_type":"code","source":"train_X_norm = x_train_norm.reshape((x_train_norm.shape[0],1, x_train_norm.shape[1]))\ntest_X_norm = x_test_norm.reshape((x_test_norm.shape[0],1, x_test_norm.shape[1]))\nprint(train_X_norm.shape, y_train.shape, test_X_norm.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c5e6d187f4f4075a322991ae7e1317b6cf08fd6"},"cell_type":"code","source":"model3 = Sequential()\nmodel3.add(GRU(32,dropout=0.2,recurrent_dropout=0.2,\n               input_shape=(train_X_norm.shape[1],\n                            train_X_norm.shape[2])))\nmodel3.add(Dense(1))\nmodel3.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62c7fb082422a2dce0fedab17e82efe09a222f71"},"cell_type":"code","source":"model3.compile(optimizer=optimizers.RMSprop(lr=0.001), loss='MAE')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e8fbe849a0fcb2ff123f271dd1615330d9803ff"},"cell_type":"code","source":"model3.fit(train_X_norm, y_train, batch_size=70, epochs =20,\n           validation_split=0.1, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9126f094d083077853442c15aa3df9ecdd87dc40"},"cell_type":"code","source":"pred3 = model3.predict(test_X_norm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2d8a06453a018333b44943d0b51b2949d92ae61"},"cell_type":"code","source":"#test_X_reg = test_X_norm.reshape((test_X_norm.shape[0], test_X_norm.shape[2]))\n#test_X_reg.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6448a0a706285453296460002f58fe64af56e608"},"cell_type":"code","source":"#inv_yhat = concatenate([pred3, test_X_reg], axis = 1)\n#inv_yhat = scaler.inverse_transform(inv_yhat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"deb3068b7cbbf69d8634a9e1bdbbc22e95ea97fe"},"cell_type":"code","source":"#test_X_norm.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69086b4b9ef1fd782f225a130d65aabcce124520"},"cell_type":"code","source":"columns_new = ['temperature']\npredict3 = pd.DataFrame(pred3, columns=columns_new)\nsubmission3 = pd.concat([submission,predict3], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef951f2b72a8bf35905f460b01a2d3af8171f743"},"cell_type":"code","source":"submission3.to_csv('submission3.csv', index= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ad8e2930a5fef939508ae50061b07321a3f9d87"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}